---
title: "run in bioinfo parallel"
author: "Emmerson Wilson"
date: "2024-08-27"
output: html_document
---

note: if you terminate a code chunk you have to restart the session!
else the future Rscipts keep running


```{r}
pacman::p_load(
  tidyverse,
  deSolve,
  parallel,
  pbapply,
  future.apply,
  progressr)
```

# model
## structure
```{r}
lv <- function(times, state, parms) {
  with(as.list(c(state, parms)), {
# moose
    Consumption    <- ((a * Pyoung)/(1 + a * h * Pyoung)) * Moose
    Death <- lM * (Moose^2)
    
    # palatable 
    GrowthPy <- rPy * Pyoung * (1 - (Pyoung + Pmature + alphaUPy * Unpal)/kPy)
    NewSeed <- s * Pmature
    DeathPy <- lPy * Pyoung
    GrowthPm <- rPm * Pmature * (1 - (Pyoung + Pmature + alphaUPm * Unpal)/kPm)
    Ageing <- g*(g^(3*(Consumption)/(Pyoung+0.01))) * Pyoung #need to add small amount to Pyoung in denominator
    DeathPm <- lPm * Pmature
    
    # unpalatable
    GrowthU <- rU * Unpal * (1 - (alphaPyU * Pyoung + alphaPmU * Pmature + Unpal)/kU)
    DeathU <- lU * Unpal

    # odes
    dMoose  <- Consumption*e - Death 
    dPyoung <- GrowthPy + NewSeed - Consumption - Ageing - DeathPy
    dPmature <- GrowthPm + Ageing - DeathPm
    dUnpal <- GrowthU - DeathU
    

    list(c(dMoose, dPyoung, dPmature, dUnpal))
  })
}
```

## parameters
```{r}
parms  <- c(a = 0.9985, 
            h = 0.0223,
            e = 0.02,
            lM = 0.3234,
            rPy = 0.2,
            rPm = 0.14,
            s = 0.011,
            alphaUPy = 0.001,
            alphaUPm = 0.0001, 
            kPy = 1000,
            kPm = 68000, 
            g = 0.133,
            lPm = 0.01,
            lPy = 0.2,
            rU = 0.9,
            alphaPyU = 0.002, 
            alphaPmU = 0.006, 
            kU = 900,
            lU = 0.4)
```

## initial conditions
```{r}

y_0 <- c(Moose =2, Pyoung = 50, Pmature = 0, Unpal = 100)
```

## extinction
```{r}
eps <- 1e-2
## event triggered if state variable <= eps
eventfun <- function(times, y, parms) {
  y[which(y<eps | y<0)] <- 0 
  return(y)
}
```

## time
```{r}
time_vec1 <- seq(from = 1, to = 1000, length.out = 1000)
```


## run model
```{r message=FALSE, include=FALSE}
out2 <- ode(y = y_0, times = time_vec1, func = lv, parms = parms, method = "lsode", events=list(func = eventfun, time = time_vec1), atol = 1e-21)

plot(out2)
```
# functions

## run model over different conditions
```{r}
ode_reps <- function(parameters, initial_conditions) {
  out <- ode(y = initial_conditions, times = time_vec1, func = lv, parms = parameters, events=list(func = eventfun, time = time_vec1), method = "lsode", atol = 1e-21)
}
```

## return year simulation becomes stable
```{r}
# using delta
return_year_stable_delta <- function(odes) {

  args_recover_delta <- as.data.frame(odes) %>% 
    mutate(dMoose = odes[,2] - lag(odes[,2]), dPyoung = Pyoung - lag(Pyoung), dPmature = Pmature - lag(Pmature), dUnpal = Unpal - lag(Unpal)) %>% 
    filter(if_all(c(6:9), ~. <= 1e-8 | is.nan(.)))
  
  args_recover_deltayr <- args_recover_delta[1,1]
  return(args_recover_deltayr)
}


# using cv
# function
# return_year_stable_cv <- function(odes) {
#   test_rollcv <- rollapply(odes, width=10, FUN=cv, fill=NA, by.column = T)
#   
#   test_rollcv_stop <- test_rollcv %>% 
#     as.data.frame() %>% 
#     mutate(time = rownames(.)) %>% 
#     filter(if_all(c(2:5), ~. <= 0.001 | is.nan(.))) # change this to be more in line with rootSolve and deSolve steady state criteria
#   
#   test_rollcv_stopyr <- test_rollcv_stop[1,1]
#   return(test_rollcv_stopyr)
# }
# 
# cv <- function(x)  sd(x)/mean(x)
```

## specifically for params

### repeat over set params
```{r}
# to repeat ode over initial conditions and parameter values with one parameter set
ode_fvsg <- function(param_list_error, init_cond) {

  out_param2 <- lapply(init_cond, ode_reps, parameters = param_list_error)
  
  names(out_param2) <- seq(1, length(y_0d_par), by = 1)
  out_param_less2 <- lapply(purrr::discard(out_param2, ~nrow(.) < 3),tail, 1, SIMPLIFY = T) 
  
  names(out_param_less2) <- paste(names(out_param_less2), ifelse(map(out_param_less2, pluck, 4) > 0, "forest", "grassland"))
  
  
  g_vs_f_param2 <- data.frame(id = parse_number(names(out_param_less2)), g_or_f = str_remove_all(names(out_param_less2), "[:digit:]")) %>% 
    left_join(y_0d_par_id) %>% 
    mutate(Moose = unlist(map(y_0d_par, pluck, 1)), By = unlist(map(y_0d_par, pluck, 2))) %>% 
    dplyr::select(!c(1,4,5,6))
  
  
  return(g_vs_f_param2)
}
```

### calculate percent recovered
```{r}
# to calculate percent recovered
percent_recover_param <- function(x) {
  df_list <- list()
  n_rec_list <- list()
  for(i in 1:ncol(x)){
  df_list[[i]] <- as.data.frame(do.call(cbind, x[,i]))
  n_rec_list[[i]] <- nrow(filter(df_list[[i]], g_or_f == " forest"))/nrow(df_list[[i]])
  }
  return(n_rec_list)
}
```



### run ode_fvsg and percent_recover_param over each param
```{r}
# to run above and create graph
param_recovery <- function(parameter){

  value_list <- as.list(signif(seq(from = param_dist[parameter,'min'], to = param_dist[parameter,'max'], by = (param_dist[parameter,'max'] - param_dist[parameter,'min'])/10),4))

  param_list <- rep(list(list()), length(value_list))
  
  for(i in 1:length(value_list)){
   param_list[[i]] <- sampled_param_list_final
    for(j in 1:length(sampled_param_list_final)){
     param_list[[i]][[j]][[parameter]] <- value_list[[i]]
    }
  }
    
  # set up clusters
# run over params and init conditions
  
  out_param2 <- rep(list(list()), length(value_list))
  percent_rec <- rep(list(list()), length(value_list))
  
  for(i in 1:length(value_list)) {
  plan(multisession, workers = 20)
  set.seed(123)
  
  #out_param2[[i]] <- future_mapply(ode_reps, parameters = param_list[[i]], initial_conditions = y_0d_par, future.seed = TRUE)
  out_param2[[i]] <- future_lapply(param_list[[i]], FUN = ode_fvsg, init_cond = y_0d_par, future.seed = TRUE)

  
  percent_rec[[i]] <- future_lapply(out_param2[[i]], FUN = function(x) nrow(filter(x, g_or_f == " forest"))/nrow(x) , future.seed = TRUE)
  
  names(percent_rec) <- c(value_list[[1]], value_list[[2]])

  plan(sequential)
}
  # 
  # names(out_param2) <- seq(1, length(y_0d_par), by = 1)
  # out_param_less2 <- purrr::discard(out_param2[[1]], ~nrow(.) < 3)
  # out_param_less_last2 <- future_lapply(out_param_less2,tail, 1, SIMPLIFY = T, future.seed = T) 
  # 
  # names(out_param_less_last2) <- paste(names(out_param_less_last2), ifelse(map(out_param_less_last2, pluck, 4) > 0, "forest", "grassland"))
# 
#   
#   g_vs_f_param2 <- data.frame(id = parse_number(names(out_param_less_last2)), g_or_f = str_remove_all(names(out_param_less_last2), "[:digit:]")) %>% 
#     left_join(y_0d_par_id) %>% 
#     mutate(Moose = unlist(map(y_0d_par, pluck, 1)), By = unlist(map(y_0d_par, pluck, 2))) %>% 
#     dplyr::select(!c(1,4,5,6))
  
  
  #g_vs_f <- future_mapply(ode_fvsg, param_list_error = param_list, init_cond = y_0d_par, future.seed = TRUE)


  recover_df <- as.data.frame(do.call(rbind, percent_rec)) %>% 
   mutate(parameter = rownames(.)) %>% 
    mutate(across(contains("V"), ~ unlist(.))) %>% 
   pivot_longer(cols = !c("parameter"), names_to = "rep", values_to = "recover")
   
  return(recover_df)
}


#plot(recover_df$parameter, recover_df$recover)
```

#### try seperating out into smaller fucntions
```{r}
# make list of parameters

param_list_combos <- function(parameter){

  value_list <- as.list(signif(seq(from = param_dist[parameter,'min'], to = param_dist[parameter,'max'], by = (param_dist[parameter,'max'] - param_dist[parameter,'min'])/10),4))

  param_list <- rep(list(list()), length(value_list))
  
  for(i in 1:length(value_list)){
   param_list[[i]] <- sampled_param_list_final
    for(j in 1:length(sampled_param_list_final)){
     param_list[[i]][[j]][[parameter]] <- value_list[[i]]
    }
  }
  names(param_list) <- value_list
  return(param_list)
}

#a_param_list_combos <- param_list_combos('a')

# run over params and inti cond
param_init_runode <- function(parameter_list){
  
  out_param2 <- rep(list(list()), length(parameter_list))
  
  for(i in 1:length(parameter_list)) {
  plan(multisession, workers = 20)
  set.seed(123)
  
  #out_param2[[i]] <- future_mapply(ode_reps, parameters = param_list[[i]], initial_conditions = y_0d_par, future.seed = TRUE)
  out_param2[[i]] <- future_lapply(parameter_list[[i]], FUN = ode_fvsg, init_cond = y_0d_par, future.seed = TRUE)
  }
  names(out_param2) <- names(parameter_list)
  return(out_param2)
}


#a_param_list_combos12 <- lapply(list(a_param_list_combos[[1]], a_param_list_combos[[2]]), function(x) x[c(3,4)])


#a_param_ode <- param_init_runode(a_param_list_combos12)



# get percent recovered
get_percent_param_rec <- function(param_ode_out, parameter_list) {
  
  percent_rec <- rep(list(list()), length(parameter_list))

 for(i in 1:length(parameter_list)) {
  
  percent_rec[[i]] <- future_lapply(param_ode_out[[i]], FUN = function(x) nrow(filter(x, g_or_f == " forest"))/nrow(x) , future.seed = TRUE)
  names(percent_rec) <- names(parameter_list)
  plan(sequential)
 }
  names(percent_rec) <- names(parameter_list)
  
  recover_df <- as.data.frame(do.call(rbind, percent_rec)) %>% 
   mutate(parameter = as.numeric(rownames(.))) %>% 
    mutate(across(contains("V"), ~ unlist(.))) %>% 
   pivot_longer(cols = !c("parameter"), names_to = "rep", values_to = "recover") %>% 
    mutate(recover = as.numeric(recover))
   
  return(recover_df)
}

#a_perc_rec <- get_percent_param_rec(a_param_ode, a_param_list_combos12)
```



### plot effect of params on recovery
```{r}
plot_effect_param <- function(data) {
 ggplot(data, aes(x = parameter, y = recover, colour = recover)) +
  geom_violin() +
  geom_jitter(width = 0.05, height = 0, size = 1) +
  scale_fill_gradient2(high = "#4D8F26", low = "#f29414", mid = "#f3f59e", midpoint = 50) +
  geom_point(stat = 'summary', fun = 'mean', size = 2) 
}
```

###  time to recovery for params
```{r}
# function to get 
param_time_rec <- function(param_list_error) {
  out_param2 <- lapply(y_0d_par, ode_reps, parameters = param_list_error)
  
  names(out_param2) <- seq(1, length(y_0d_par), by = 1)
  out_param_less2 <- purrr::discard(out_param2, ~nrow(.) < 3)
  
  out_param_less_last2 <- lapply(out_param_less2,tail, 1, SIMPLIFY = T) 
  
  names(out_param_less2) <- paste(names(out_param_less_last2), ifelse(map(out_param_less_last2, pluck, 4) > 0, "forest", "grassland"))
  
  args_recover <- out_param_less2[ ! names(out_param_less2) %>% str_detect("grassland") ]
  
  args_recover_yr <- lapply(args_recover, return_year_stable_delta)
  
  args_recover_yravg <- mean(as.numeric(args_recover_yr))
  
  return(args_recover_yravg)
}
```

### run param_time_rec over each param
```{r}
return_year_stable_param <- function(param) {
  param_listat <- list(rep(list(),11))
  
  value_listat <- as.list(signif(seq(from = param_dist[param,'min'], to = param_dist[param,'max'], by = (param_dist[param,'max'] - param_dist[param,'min'])/10),4))
  
  for(i in 1:length(value_listat)){
    param_listat[[i]] <- sampled_param_list_final[seq(1, length(sampled_param_list_final), 10)] # will not be seq for full simulation
    for(j in 1:length(sampled_param_list_final[seq(1, length(sampled_param_list_final), 10)])){
      param_listat[[i]][[j]][['a']] <- value_listat[[i]]
    }
  }
  
  gf_param_yr <- lapply(param_listat, sapply, param_time_rec) 
  names(gf_param_yr) <- value_listat
  
  
  gf_param_yrdf <- as.data.frame(do.call(rbind, gf_param_yr)) %>% 
    mutate(parameter = rownames(.)) %>% 
    pivot_longer(cols = !c("parameter"), names_to = "rep", values_to = "yr_recover")

}
```

### plot effect of params on time
```{r}
plot_effect_param_t <- function(data) {
 ggplot(data, aes(x = parameter, y = yr_recover, colour = yr_recover)) +
  geom_violin() +
  geom_jitter(width = 0.05, height = 0, size = 1) +
  scale_fill_gradient(low = "#421650", high = "white", na.value = "#C4C4C4") +
  geom_point(stat = 'summary', fun = 'mean', size = 2) 
}

```

# ranges

## initial conditions
```{r}
# make dataframe with sequence of initial conditions to sample over
# always starting from no mature and some level of unpal
# smallest values 0 for both, moose up to 6 Mg moose, and 500 Py

n_i <- 30

M_init <- seq(0, 6, length.out = n_i)
Py_init <- seq(0, 300, length.out = n_i) 
Pm_init <- rep(0, n_i)
U_init <- rep(100, n_i)

init_seq <- data.frame(Moose=rep(M_init, each = n_i), Pyoung = rep(Py_init, n_i), Pmature = rep(Pm_init,n_i), Unpal = rep(U_init,n_i))

y_0d <- split(as.matrix(init_seq), row(init_seq)) %>% 
  lapply(setNames, nm = c("Moose", "Pyoung", "Pmature", "Unpal"))

y_0d_id <- as.data.frame(t(as.data.frame(y_0d))) %>% 
  mutate(id = seq(1, length(y_0d), by = 1))
```

## parameters
```{r}
# make datafram with distribution of parameters

LVlow <-  c(0.996, #a
            0.0207933, # h
            0.01, #e
            0.2647, # lM
            0.15, #rPy
            0.1, #rPm
            0.0088, #s
            0.0005, #alphaUPy
            0.000, #alphaUPm
            400, #kPy
            20000, # kPm
            0.09, # g
            0.005, #lPm
            0.1, #lPy
            0.6,#rU
            0.001, # alphaPyU
            0.004, # alphaPmU
            300, #kU
            0.168) #lU

LVhigh <-  c(1.005, #a
            0.038735, # h
            0.03, #e
            0.3765, # lM
            0.325, #rPy
            0.2, #rPm
            0.053, #s
            0.002, #alphaUPy
            0.0002, #alphaUPm
            2000, #kPy
            80000, # kPm
            0.2, # g
            0.06, #lPm
            0.3, #lPy
            1.3 ,#rU
            0.003, # alphaPyU
            0.008, # alphaPmU
            1200, #kU
            1) #lU


param_dist <- data.frame(min = LVlow, max = LVhigh, mean = parms)

library(truncnorm)
```
### how many samples
number of parameter combos vs number recovered
```{r}
## for n samples of random parameter combos vs n recover
set.seed(123)

# make list of number of sampls to try
n_p_list <- as.list(c(rgamma(18, 4, 0.035), 300, 500))
saveRDS(n_p_list, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/n_p_list.RDS") 

# function to repeat ode across initial conditions and each combination of parameters, for each number of samples in list 

rep_over_n_param_samples <- function (n_param) {
  
# make n random combinations of paramaters
  n_p <- n_param
  
  sampled_param <-  list()
  
# sample from distribution of each parameter n times
  for(i in rownames(param_dist)){
    set.seed(123)
    sampled_param[[i]] <- signif(rtruncnorm(n=n_p, a=param_dist[[i,1]], b=param_dist[[i,2]], mean=param_dist[[i,3]],  sd=(param_dist[[i,2]]-param_dist[[i,1]])/5), 5)
  }

# make list of possible parameter combinations
  sampled_param_list <-  split(as.matrix(as.data.frame(sampled_param)), row(as.data.frame(sampled_param))) %>% 
    lapply(setNames, nm = names(parms))
  
  sampled_param_list_final <- list()
  # remove combinations that don't meet assumptions (around competative effects, growth rates, carrying capacities, and death rates)
  
  # relative growth rate
  sampled_param_list2 <-  sampled_param_list[sapply(sampled_param_list, `[`, 'rPy') < sapply(sampled_param_list, `[`, 'rU') & sapply(sampled_param_list, `[`, 'rPm') < sapply(sampled_param_list, `[`, 'rPy')]
  
  # competative effects
  sampled_param_list3 <-  sampled_param_list2[sapply(sampled_param_list2, `[`, 'alphaUPm') < sapply(sampled_param_list2, `[`, 'alphaUPy') & sapply(sampled_param_list2, `[`, 'alphaUPy') < sapply(sampled_param_list2, `[`, 'alphaPyU') & sapply(sampled_param_list2, `[`, 'alphaPyU') < sapply(sampled_param_list2, `[`, 'alphaPmU')]
  
  # carrying capacities
  sampled_param_list4 <-  sampled_param_list3[sapply(sampled_param_list3, `[`, 'kU') < sapply(sampled_param_list3, `[`, 'kPy') & sapply(sampled_param_list3, `[`, 'kPy') < sapply(sampled_param_list3, `[`, 'kPm')]
  
  # loss
  sampled_param_list_final <-  sampled_param_list4[sapply(sampled_param_list4, `[`, 'lPm') < sapply(sampled_param_list4, `[`, 'lU')]

  # combine with initial values (constant) 
  args <- expand.grid(
    parameters=sampled_param_list_final,
    initial_conditions=y_0d) 
  args_id <- args %>% mutate(id = seq(1, nrow(args), by = 1))
  list2env(args, envir=.GlobalEnv)


# run over params and init conditions
  plan(multisession, workers = 24)
  set.seed(123)

  args$output <- future_mapply(ode_reps, parameters, initial_conditions, SIMPLIFY = F, future.seed = TRUE) 

  plan(sequential)
  
# give simulations names based params and init conditions
  names(args$output) <- seq(1, nrow(args_id), by = 1)

# remove any simulations that didnt run properly
  args_less <- purrr::discard(args$output, ~nrow(.) < 3)
  arg_removed <- purrr::keep(args$output, ~nrow(.) < 3)


# remove simulations that didn't reach steady state
  plan(multisession, workers = 24)
  set.seed(123)
  
  args_less_steady_NAs <- future_lapply(args_less, return_year_stable_delta, future.seed = TRUE) # this function returns NAs if the simulation doesn;t reach steady state

  args_less_steady <- args_less[!is.na(args_less_steady_NAs)]

  plan(sequential)


# # get final stocks from remaining simulations
  plan(multisession, workers = 24)
  set.seed(123)
  
  arg_less_last <- future_lapply(args_less_steady,tail, 1, SIMPLIFY = T, future.seed = TRUE)
  
  plan(sequential)

# make this info a heat map

# if pmature = 0, and/or Unpal ≠ 0 then grassland
# if pmature ≠ 0 then forest

  names(arg_less_last) <- paste(names(arg_less_last), ifelse(map(arg_less_last, pluck, 4) > 0, "forest", "grassland"))

# add info on initial conditions
  g_vs_f <- data.frame(id = parse_number(names(arg_less_last)), g_or_f = str_remove_all(names(arg_less_last), "[:digit:]")) %>% 
   left_join(args_id) %>% 
   mutate(Moose = unlist(map(initial_conditions, pluck, 1)), By = unlist(map(initial_conditions, pluck, 2))) %>% 
   dplyr::select(!c(1,3,4))

# count number of recoveries
  n_g_vs_f <- g_vs_f %>% 
    group_by(as.factor(Moose), as.factor(By), as.factor(g_or_f), .drop=FALSE) %>% 
    count(.drop=FALSE) %>% 
    ungroup() %>% 
    mutate(Moose = as.numeric(as.character(`as.factor(Moose)`))) %>% 
   mutate(By = as.numeric(as.character(`as.factor(By)`))) %>% 
   rename(g_or_f = `as.factor(g_or_f)`) %>% 
   dplyr::select(c(3:6))

# count total number recovered for all simulations relative to number of simulations
  percent_rec <- sum(filter(n_g_vs_f, g_or_f == " forest")$n)/sum(n_g_vs_f$n)

  
  return(percent_rec)
}


# library(parallel)
# library(doParallel)
# library(snow)
# library(pbapply)
# 
# 
# cl <- makeCluster(20, "SOCK")
# clusterExport(cl,list=list('n_p_list_test', 'rep_over_n_param_samples', 'param_dist', 'sampled_param', 'parms', 'y_0dtest', 'ode_reps', 'lv', 'time_vec1', 'eventfun', 'eps'), envir=environment())
# 
# parallel::clusterEvalQ(cl, c(library(truncnorm)))
# parallel::clusterEvalQ(cl, c(library(dplyr)))
# parallel::clusterEvalQ(cl, c(library(dplyr)))
# parallel::clusterEvalQ(cl, c(library(deSolve)))
# 
# 
# n_p_recoveries <- pblapply(FUN=rep_over_n_param_samples, n_p_list, cl = cl)



# run function
n_p_recoveries <- lapply(n_p_list, rep_over_n_param_samples)


lower_list <- as.list(c(10,20)
                      )

low_n_p_recoveries <- lapply(lower_list, rep_over_n_param_samples)

# set up clusters
#   plan(multisession, workers = 24)
#   set.seed(123)
# 
# # run function
# n_p_recoveries <- future_lapply(n_p_list, rep_over_n_param_samples,  future.seed = TRUE)

plot(n_p_list, n_p_recoveries)

plan(sequential)

# nprec_test <- pblapply(n_p_list_test, rep_over_n_param_samples)
saveRDS(n_p_recoveries, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/n_p_recoveries.RDS") 
saveRDS(low_n_p_recoveries, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/low_n_p_recoveries.RDS") 
  
  
n_p <- data.frame(list = unlist(n_p_list), recov = unlist(n_p_recoveries))
n_p_low <- data.frame(list = unlist(lower_list), recov = unlist(low_n_p_recoveries))

n_p_both <- rbind(n_p, n_p_low)

ggplot(n_p, aes(x = list, y = recov))+ 
   geom_point() + 
   geom_smooth(method = "nls", 
              formula = y ~  (a*x) / (b + x),
              se = FALSE,
              method.args = list(start = list(a = 0.771, b = 50))) +
  xlim(c(0,500))

ggplot(n_p, aes(x = list, y = recov))+ 
   geom_point() + 
   geom_smooth() +
  geom_hline(yintercept = mean(n_p$recov))  +
  xlim(c(0,500))

```



### list for heatmap
```{r}
sampled_param <- list()

n_p <- 150 # may change

for(i in rownames(param_dist)){
sampled_param[[i]] <- signif(rtruncnorm(n=n_p, a=param_dist[[i,1]], b=param_dist[[i,2]], mean=param_dist[[i,3]],  sd=(param_dist[[i,2]]-param_dist[[i,1]])/5), 5)
}

sampled_param_list <-  split(as.matrix(as.data.frame(sampled_param)), row(as.data.frame(sampled_param))) %>% 
  lapply(setNames, nm = names(parms))

sampled_param_list_final <- list()

# remove combinations that don't meet assumptions (around competative effects, growth rates, carrying capacities, and death rates)

# relative growth rate
sampled_param_list2 <-  sampled_param_list[sapply(sampled_param_list, `[`, 'rPy') < sapply(sampled_param_list, `[`, 'rU') & sapply(sampled_param_list, `[`, 'rPm') < sapply(sampled_param_list, `[`, 'rPy')]

# competative effects
sampled_param_list3 <-  sampled_param_list2[sapply(sampled_param_list2, `[`, 'alphaUPm') < sapply(sampled_param_list2, `[`, 'alphaUPy') & sapply(sampled_param_list2, `[`, 'alphaUPy') < sapply(sampled_param_list2, `[`, 'alphaPyU') & sapply(sampled_param_list2, `[`, 'alphaPyU') < sapply(sampled_param_list2, `[`, 'alphaPmU')]

# carrying capacities
sampled_param_list4 <-  sampled_param_list3[sapply(sampled_param_list3, `[`, 'kU') < sapply(sampled_param_list3, `[`, 'kPy') & sapply(sampled_param_list3, `[`, 'kPy') < sapply(sampled_param_list3, `[`, 'kPm')]


# loss
sampled_param_list_final <-  sampled_param_list4[sapply(sampled_param_list4, `[`, 'lPm') < sapply(sampled_param_list4, `[`, 'lU')]
```


# initial conditions effects

## heatmap
```{r}
## give some result at each step so know loops aren't getting stuck
# make ode into function where parameters and initial conditions can be used
out_end <- list()                     
out <- list()        

# make all combinations availabel in environment
args <- expand.grid(
  parameters=sampled_param_list_final,
  initial_conditions=y_0d) 
args_id <- args %>% mutate(id = seq(1, nrow(args), by = 1))
list2env(args, envir=.GlobalEnv)

# set up clusters
plan(multisession, workers = 15)
set.seed(123)

# handlers(global = TRUE)
# handlers("progress")
# 
# 
# progress_fucntion <- function(param, init) {
#   p <- progressor(along = init)
#   y <- future_mapply(ode_reps, param, init, SIMPLIFY = F)
#   p()
#   return(y)
# }
# 
# args$output <- progress_fucntion( parameters, initial_conditions)

# run over params and init conditions
args$output <- future_mapply(ode_reps, parameters, initial_conditions, SIMPLIFY = F,  future.seed = TRUE) # add progress bar or periodic outputs and try to make parallel
#can;t use progress bar and parallel with mapply



# library(parallel)
# library(doParallel)
# library(snow)
# library(pbapply)
# 
# 
# cl <- makeCluster(20, "SOCK")
# clusterExport(cl,list=list('parameters', 'initial_conditions', 'ode_reps'))
# 
#  
# args$output<- pbmapply(FUN=ode_reps, parameters, initial_conditions, cl = cl)
# 
# args$output <- mapply(ode_reps, parameters, initial_conditions, SIMPLIFY = F) 

# give simulations names based params and init conditions
names(args$output) <- seq(1, nrow(args_id), by = 1)

# remove any simulations that didnt run properly
args_less <- purrr::discard(args$output, ~nrow(.) < 3)
arg_removed <- purrr::keep(args$output, ~nrow(.) < 3)


# remove simulations that didn't reach steady state

args_less_steady_NAs <- future_lapply(args_less, return_year_stable_delta, future.seed = TRUE) # this function returns NAs if the simulation doesn;t reach steady state

args_less_steady <- args_less[!is.na(args_less_steady_NAs)]


# # get final stocks from remaining simulations
arg_less_last <- future_lapply(args_less_steady,tail, 1, SIMPLIFY = T)


plan(sequential)
# make this info a heat map

# if pmature = 0, and/or Unpal ≠ 0 then grassland
# if pmature ≠ 0 then forest

names(arg_less_last) <- paste(names(arg_less_last), ifelse(map(arg_less_last, pluck, 4) > 0, "forest", "grassland"))

# add info on initial conditions
g_vs_f <- data.frame(id = parse_number(names(arg_less_last)), g_or_f = str_remove_all(names(arg_less_last), "[:digit:]")) %>% 
  left_join(args_id) %>% 
  mutate(Moose = unlist(map(initial_conditions, pluck, 1)), By = unlist(map(initial_conditions, pluck, 2))) %>% 
  dplyr::select(!c(1,3,4))


# count number of recoveries
n_g_vs_f <- g_vs_f %>% 
  group_by(as.factor(Moose), as.factor(By), as.factor(g_or_f), .drop=FALSE) %>% 
  count(.drop=FALSE) %>% 
  ungroup() %>% 
  mutate(Moose = as.numeric(as.character(`as.factor(Moose)`))) %>% 
  mutate(By = as.numeric(as.character(`as.factor(By)`))) %>% 
  rename(g_or_f = `as.factor(g_or_f)`) %>% 
  dplyr::select(c(3:6))

# number of simulations

n_s <- g_vs_f %>% 
  group_by(as.factor(Moose), as.factor(By), .drop=FALSE) %>% 
  count(.drop=FALSE) %>% 
  ungroup() %>% 
  mutate(Moose = as.numeric(as.character(`as.factor(Moose)`))) %>% 
  mutate(By = as.numeric(as.character(`as.factor(By)`))) %>% 
  rename(ns = n) %>% 
  dplyr::select(c(3:5))

# into %
n_fs <- n_g_vs_f %>% 
  inner_join(n_s) %>% 
  subset( g_or_f == " forest") %>% 
  mutate(percent_recover = (n/ns*100) )



# mark 50/50


n_f2 <- n_fs %>% 
  filter(percent_recover >= 50) %>% 
  group_by(Moose,  .drop=FALSE) %>% 
  filter(By == min(By)) %>%
  mutate(Moose = Moose - 0.2068966/2, By = By - 10.34483/2	) %>%
  arrange(Moose)

n_f2 <- n_f2 %>% bind_rows(n_f2[nrow(n_f2), ] %>% mutate(Moose = Moose +  0.2068966))
n_f2
plan(sequential)

# make heatmap

# main fig
heatmap_moose_By <- ggplot() +
  geom_tile(data = n_fs, aes(x = Moose, y = By, fill = percent_recover)) +
  geom_step(data = n_f2, aes(x = Moose, y = By), size = 0.5) +
  scale_fill_gradient2(high = "#4D8F26", low = "#f29414", mid = "#f3f59e", midpoint = 50) +
  labs(x = "Moose biomass (Metric tons)", y = "Young palatable plant biomass (Metric tons)", fill = "Percent\nrecovered") +
  theme_classic() +
  scale_y_continuous(expand = c(0,0), limits = c(- 10.34483/2, 300)) +
  scale_x_continuous(expand = c(0,0))

heatmap_moose_By

jpeg("~/C_forecasting_NL/code_for_stats/for odes/outputs/heatmap_moose_By.jpg", height = 10, width = 15, units = "cm", res = 600)
heatmap_moose_By
dev.off()

# legend top
heatmap_moose_By <- ggplot() +
  geom_tile(data = n_fs, aes(x = Moose, y = By, fill = percent_recover)) +
  geom_step(data = n_f2, aes(x = Moose, y = By), size = 0.5) +
  scale_fill_gradient2(high = "#4D8F26", low = "#f29414", mid = "#f3f59e", midpoint = 50) +
  labs(x = "Moose biomass (Metric tons)", y = "Young palatable plant biomass (Metric tons)", fill = "Percent\nrecovered") +
  theme_classic() +
  scale_y_continuous(expand = c(0,0), limits = c(- 10.34483/2, 300)) +
  scale_x_continuous(expand = c(0,0)) + theme(legend.position = "top")

heatmap_moose_By

jpeg("~/C_forecasting_NL/code_for_stats/for odes/outputs/heatmap_moose_By.jpg", height = 13, width = 15, units = "cm", res = 600)
heatmap_moose_By
dev.off()

saveRDS(args, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/args.RDS") 

```

### plot 
```{r}
n_fs_ratio <- n_fs %>% 
  mutate(ratio = ifelse(Moose == 0 & By == 0, 0, ifelse(Moose == 0 & By != 0, 1500, By/Moose)))

#n_fs_ratio <- readRDS(file = "~/Documents/Master's/C_forecasting_NL/code_for_stats/for odes/outputs/n_fs_ratio.RDS") 

library(grid)

yaxis <- data.frame( x = rep(0, 110), y = seq(1,110, 1))

n_fs_ratio_plot <- ggplot() +
  geom_point(data = n_fs_ratio, aes(ratio, percent_recover, colour = percent_recover)) +
  scale_x_continuous(limits = c(0,50)) + #, expand = c(0,0)) +
  #scale_y_continuous(expand = c(0,0))+
  theme_classic() +
  scale_colour_gradient2(high = "#4D8F26", low = "#f29414", mid = "#f3f59e", midpoint = 50) +
  labs(x = expression(frac("Young palatable biomass (t)", "Moose biomass (t)")), y = 'Percent simulations recover', colour = 'Percent simulations recover') +
  theme(legend.position = 'none') +
  #geom_line(data = yaxis, aes(x = x, y = y, colour = y))
  coord_cartesian(clip = "off") +
  annotation_custom(grid::rectGrob(x = unit(0.007, "npc"), y = unit(0.5, "npc"),
         width = unit(2, "mm"), height = unit(73, "mm"), gp = gpar(col = NA, fill = grid::linearGradient(colour = c("#f29414", "#f3f59e", "#4D8F26"), stops = c(0, 0.5, 1)), lwd = unit(0.1, "pt"))))
  


  #gghighlight(percent_recover == 100 | percent_recover == 0)
n_fs_ratio_plot

saveRDS(n_fs_ratio, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/n_fs_ratio.RDS") 

jpeg("~/Documents/Master's/C_forecasting_NL/code_for_stats/for odes/outputs/n_fs_ratio_plot.jpg", height = 10, width = 12, units = "cm", res = 600)
n_fs_ratio_plot
dev.off()


# predict



```



## time for recovered to recover
```{r}
args_less_steady2 <- args_less_steady
names(args_less_steady2) <- names(arg_less_last)


# remove any that go to grassland
args_recover <- args_less_steady2[! names(args_less_steady2) %>% str_detect("grassland") ]

# set up clusters
plan(multisession, workers = 15)
set.seed(123)

library(zoo)

year_stable_delta <- future_lapply(args_recover, return_year_stable_delta)

plan(sequential)

# add to simulation data
f_yr <- data.frame(id = parse_number(names(year_stable_delta)), g_or_f = str_remove_all(names(year_stable_delta), "[:digit:]"), year = unlist(year_stable_delta)) %>% 
  left_join(args_id) %>% 
  mutate(Moose = unlist(map(initial_conditions, pluck, 1)), By = unlist(map(initial_conditions, pluck, 2))) %>% 
  na.omit() %>% 
  dplyr::select(!c(1,4,5))
# seems to depend mostly on parameter

avg_yr_f <- f_yr %>% 
  group_by(as.factor(Moose), as.factor(By), .drop = F) %>% 
  summarise(mean_yr = mean(as.numeric(year))) %>% 
  ungroup() %>% 
  mutate(Moose = as.numeric(as.character(`as.factor(Moose)`))) %>% 
  mutate(By = as.numeric(as.character(`as.factor(By)`))) %>% 
  dplyr::select(c(3:5))


avg_yr_50_f <- avg_yr_f %>% 
  right_join(filter(n_fs, percent_recover >= 0))
  
n_f22100 <- avg_yr_50_f %>% 
  filter(percent_recover >= 100) %>% 
  group_by(Moose,  .drop=FALSE) %>% 
  filter(By == min(By)) %>%
  mutate(Moose = Moose - 0.2068966/2, By = By - 10.34483/2	) %>%
  arrange(Moose)

n_f22100 <- n_f22100 %>% bind_rows(n_f22100[nrow(n_f22100), ] %>% mutate(Moose = Moose + 0.2068966))

# seperate colur scheme for time

heatmap_moose_By_yr <- ggplot() +
  geom_tile(data = avg_yr_50_f, aes(x = Moose, y = By, fill = mean_yr)) +
  # geom_step(data = n_f2, aes(x = Moose, y = By), size = 0.5) +
  #   geom_step(data = n_f22100, aes(x = Moose, y = By), size = 0.5, color = "white") +
  scale_fill_gradient(low = "#421650", high = "white", na.value = "#C4C4C4") +
  labs(x = "Moose biomass (Metric tons)", y = "Young palatable plant biomass (Metric tons)", fill = "Years to\nrecover") +
  theme_classic() +
  scale_y_continuous(expand = c(0, 0), limits = c(- 10.34483/2, 300)) +
  scale_x_continuous(expand = c(0,0))

heatmap_moose_By_yr

jpeg("~/C_forecasting_NL/code_for_stats/for odes/outputs/heatmap_moose_By_yr.jpg", height = 10, width = 13, units = "cm", res = 600)
heatmap_moose_By_yr
dev.off()
# will need hetmap of how many each simulation is over

saveRDS(year_stable_delta, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/year_stable_delta.RDS") 

```

```{r}
avg_yr_50_f_ratio <- avg_yr_50_f %>% 
  mutate(ratio = ifelse(Moose == 0 & By == 0, 0, ifelse(Moose == 0 & By != 0, 1500, By/Moose)))

avg_yr_50_f_ratio <- readRDS(file = "~/Documents/Master's/C_forecasting_NL/code_for_stats/for odes/outputs/avg_yr_50_f_ratio.RDS") 

avg_yr_50_f_ratioplot <- ggplot(avg_yr_50_f_ratio, aes(ratio, mean_yr, colour = mean_yr)) +
  geom_point() +
  xlab(expression(atop(paste(underline(Young~palatable~biomass~(t))), "\nMoose biomass (t)"))) +
  ylab('Year for simulation to recover')+
  scale_colour_gradient(low = "#421650", high = "white", na.value = "#C4C4C4") +
  theme_classic()
n_fs_ratio_plot

avg_yr_50_f_ratioplotz <- ggplot(avg_yr_50_f_ratio, aes(ratio, percent_recover, colour = mean_yr)) +
  geom_point() +
  xlab(expression(atop(paste(underline(Young~palatable~biomass~(t))), "\nMoose biomass (t)"))) +
  ylab('Year for simulation to recover')+
  xlim(c(0, 50))+
  scale_colour_gradient2(low = "#421650", mid = "#84678D",  high = "white", na.value = "#C4C4C4", midpoint = (max(avg_yr_50_f_ratio$mean_yr, na.rm = T) + min(avg_yr_50_f_ratio$mean_yr, na.rm = T))/2)+
  theme_classic()
n_fs_ratio_plotz
n_fs_ratio_plot

avg_yr_50_f_ratioplot2 <- ggplot() +
  geom_point(data = avg_yr_50_f_ratio, aes(ratio, mean_yr, colour = mean_yr)) +
  #scale_x_continuous(limits = c(0,50)) + #, expand = c(0,0)) +
  #scale_y_continuous(expand = c(0,0))+
  theme_classic() +
  scale_colour_gradient2(high = "#C6B9CA", low = "#290934", mid = "#84678D", midpoint = (max(avg_yr_50_f_ratio$mean_yr, na.rm = T) + min(avg_yr_50_f_ratio$mean_yr, na.rm = T))/2) +
  labs(x = expression(frac("Young palatable biomass (t)", "Moose biomass (t)")), y = 'Years to stable') +
  theme(legend.position = 'none') +
  #geom_line(data = yaxis, aes(x = x, y = y, colour = y))
  coord_cartesian(clip = "off") +
  annotation_custom(grid::rectGrob(x = unit(0.007, "npc"), y = unit(0.5, "npc"),
         width = unit(2, "mm"), height = unit(73, "mm"), gp = gpar(col = NA, fill = grid::linearGradient(colour = c("#290934", "#84678D", "#C6B9CA"), stops = c(0, 0.5, 1)), lwd = unit(0.1, "pt"))))
avg_yr_50_f_ratioplot2

saveRDS(avg_yr_50_f_ratio, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/avg_yr_50_f_ratio.RDS") 

jpeg("~/Documents/Master's/C_forecasting_NL/code_for_stats/for odes/outputs/avg_yr_50_f_ratioplot2.jpg", height = 10, width = 12, units = "cm", res = 600)
avg_yr_50_f_ratioplot2
dev.off()

avg_yr_50_f_ratioplot2z <- ggplot() +
  geom_point(data = avg_yr_50_f_ratio, aes(ratio, mean_yr, colour = mean_yr)) +
  scale_x_continuous(limits = c(0,50)) + #, expand = c(0,0)) +
  #scale_y_continuous(expand = c(0,0))+
  theme_classic() +
  scale_colour_gradient2(high = "#C6B9CA", low = "#290934", mid = "#84678D", midpoint = (max(avg_yr_50_f_ratio$mean_yr, na.rm = T) + min(avg_yr_50_f_ratio$mean_yr, na.rm = T))/2) +
  labs(x = expression(frac("Young palatable biomass (t)", "Moose biomass (t)")), y = 'Years to stable') +
  theme(legend.position = 'none') +
  #geom_line(data = yaxis, aes(x = x, y = y, colour = y))
  coord_cartesian(clip = "off") +
  annotation_custom(grid::rectGrob(x = unit(0.007, "npc"), y = unit(0.5, "npc"),
         width = unit(2, "mm"), height = unit(73, "mm"), gp = gpar(col = NA, fill = grid::linearGradient(colour = c("#290934", "#84678D", "#C6B9CA"), stops = c(0, 0.5, 1)), lwd = unit(0.1, "pt"))))
avg_yr_50_f_ratioplot2z

jpeg("~/Documents/Master's/C_forecasting_NL/code_for_stats/for odes/outputs/avg_yr_50_f_ratioplot2z.jpg", height = 10, width = 12, units = "cm", res = 600)
avg_yr_50_f_ratioplot2z
dev.off()
```


# parameter effects
## across list of parameters

# limit initial conditions
```{r}
# run lines 669 - 725 after importing RDS
args <- readRDS(file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/args.RDS") 


# get values of Moose and BY combinations that go to forest 100% or 0%
n_f_rec <- n_fs %>% 
  filter(percent_recover == 100 | percent_recover == 0) %>% 
  mutate(MPy = paste0(Moose, "_", By))

# make into list
MBy_list <- as.list(n_f_rec$MPy)

# get all combinations of initial conditions from list
y_0d_rec <- lapply(y_0d, function(x) paste0(x[[1]],"_", x[[2]]))

# remove ones that went to 100 or 0
y_0d_rec2 <- y_0d_rec[ !y_0d_rec %in% MBy_list ]

# remove y_0d_rec from y_0d based on name 
y_0d_par <- y_0d[names(y_0d) %in% names(y_0d_rec2)]

y_0d_par_id <- as.data.frame(t(as.data.frame(y_0d_par))) %>% 
  mutate(id = seq(1, length(y_0d_par), by = 1))



saveRDS(y_0d_par, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/y_0d_par.RDS") 
```



maybe take out the simulations where the ratios of Py:M where simulations always recover and always go to grassland.
only interested in the gradient section of the heatmap

```{r}
y_0d_par <- readRDS(file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/y_0d_par.RDS") 

# instead of doing forloops within function, make matrix of all combinations?

# ode_recovery <- lapply(names(parms), param_recovery)
# 
# plot_ode_recovery <- lapply(ode_recovery, plot_effect_param)
# 
# saveRDS(ode_recovery, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/ode_recovery.RDS") 
# saveRDS(plot_ode_recovery, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/plot_ode_recovery.RDS") 

# split into parts
param_combos <- lapply(names(parms), param_list_combos)
names(param_combos) <- names(parms)

for(i in 1:length(param_combos)){
  nam <- paste(names(param_combos)[i], "combos", sep = "_")
  assign(nam,param_combos[[i]])
}

# run each parameter on own? cant handle running in loop
# may need to clear 
e_combos2 <- list(e_combos[[5]], e_combos[[9]])
names(e_combos2) <- c(names(e_combos)[[5]],names(e_combos)[[9]])

e_combos_ode <- param_init_runode(e_combos)
e_combos_rec <- get_percent_param_rec(e_combos_ode, e_combos)

ggplot(e_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
remove(e_combos_ode)
saveRDS(e_combos_rec, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/e_combos_rec.RDS") 


rU_odes <- param_init_runode(rU_combos)
rU_combos_rec <- get_percent_param_rec(rU_odes, rU_combos)
ggplot(rU_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
saveRDS(rU_combos_rec, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/rU_combos_rec.RDS") 



remove(rU_odes)

rPy_odes <- param_init_runode(rPy_combos)
rPy_combos_rec <- get_percent_param_rec(rPy_odes, rPy_combos)
remove(rPy_odes)
ggplot(rPy_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
saveRDS(rPy_combos_rec, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/rPy_combos_rec.RDS") 


lU_odes <- param_init_runode(lU_combos)
lU_combos_rec <- get_percent_param_rec(lU_odes,lU_combos)
remove(lU_odes)
ggplot(lU_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
saveRDS(lU_combos_rec, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/lU_combos_rec.RDS") 


lPy_odes <- param_init_runode(lPy_combos)
lPy_combos_rec <- get_percent_param_rec(lPy_odes,lPy_combos)
remove(lPy_odes)
ggplot(lPy_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
saveRDS(lPy_combos_rec, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/lPy_combos_rec.RDS") 


lPm_odes <- param_init_runode(lPm_combos)
lPm_combos_rec <- get_percent_param_rec(lPm_odes,lPm_combos)
remove(lPm_odes)
ggplot(lPm_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))


lM_odes <- param_init_runode(lM_combos)
lM_combos_rec <- get_percent_param_rec(lM_odes,lM_combos)
remove(lM_odes)
ggplot(lM_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))

kU_odes <- param_init_runode(kU_combos)
kPy_odes <- param_init_runode(kPy_combos)
kPm_odes <- param_init_runode(kPm_combos)

h_odes <- param_init_runode(h_combos)
h_combos_rec <- get_percent_param_rec(h_odes, h_combos)
ggplot(h_combos_rec, aes(parameter, recover)) +
  geom_violin(aes(factor(parameter)))
remove(h_odes)

g_odes <- param_init_runode(g_combos)
e_odes <- param_init_runode(e_combos)
alphaUpy_odes <- param_init_runode(alphaUpy_combos)
alphaUPm_odes <- param_init_runode(alphaUPm_combos)
alphaPyU_odes <- param_init_runode(alphaPyU_combos)
alphaPmU_odes <- param_init_runode(alphaPmU_combos)
a_odes <- param_init_runode(a_combos)





# run through for loop 
# for(i in 1:length(param_combos)) {
#   param_combos_ode <- list()
#   nam <- paste(names(param_combos)[i], "odes", sep = "_")
#   
#   param_combos_ode[[i]] <- param_init_runode(param_combos[[i]])
#   
#   assign(nam,param_combos_ode[[i]])
# }
# 
# 
# list_param_ode_names <- lapply(names(parms), function (x) paste(x, "odes", sep = "_"))
# 
# 
# lapply(list_param_ode_names, get_percent_param_rec, param_combos)
```


## time to recovery based on parameters
```{r}
# set up clusters
plan(multisession, workers = 15)
set.seed(123)
# to return year stable for each parameter and plot
param_recoveryt <- future_lapply(names(parms2), return_year_stable_param)

plot_ode_recoveryt <- future_lapply(param_recoveryt, plot_effect_param_t)

saveRDS(ode_recoveryt, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/ode_recoveryt.RDS") 
saveRDS(plot_ode_recoveryt, file = "~/C_forecasting_NL/code_for_stats/for odes/outputs/plot_ode_recoveryt.RDS") 

plan(sequential)
```



